{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TGroup_Stats.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ense-nastydev/ChatAnalytics/blob/main/TGroup_Stats.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpQCEXMw53BA"
      },
      "source": [
        "# Telegram chat analytics with Pandas\n",
        "\n",
        "This notebook is still a work in progress. we can now proces the machine readable json from a chat export file created with Telegram desktop. \n",
        "\n",
        "The easiest way to get going is to open this notebook in colaboratory and upload your chat export file (result.json) to the created instance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLMTDVtJsW4k"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Install missing software and up to date libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq6DVdTJFUzU"
      },
      "source": [
        "%%bash\n",
        "pip install boltons more-itertools  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiCIUEXltKBY"
      },
      "source": [
        "Also upload the data to work on to your instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qxLFZLAbeS6"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print(\n",
        "        'User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "            name=fn, length=len(uploaded[fn])\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpBHKIU1tbt2"
      },
      "source": [
        "# Data Processing\n",
        "\n",
        "make  lazy json loader and use it to feed a pandas dataframe.\n",
        "This dataframe will get transformed in a variety o ways for analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONdyasz0tVJ4"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUA6JhoriqaN"
      },
      "source": [
        "from datetime import datetime\n",
        "from boltons.iterutils import windowed_iter\n",
        "\n",
        "\n",
        "def gendeltas(timestamps_object, objname):\n",
        "    \"\"\"Generates a column with time deltas calculated from the current\n",
        "    and previous timestamp value. First timedelta is always 0\"\"\"\n",
        "    a = datetime.now()\n",
        "    deltas = [a - a]\n",
        "    for older, newer in windowed_iter(timestamps_object, 2):\n",
        "        deltatime = datetime.fromisoformat(newer) - datetime.fromisoformat(older)\n",
        "        if deltatime >= (a - a):\n",
        "            deltas.append(deltatime)\n",
        "        else:\n",
        "            deltas.append(a - a)\n",
        "    deltasS = pd.Series(\n",
        "        deltas,\n",
        "        name=objname,\n",
        "    )\n",
        "    return deltasS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dkGqwqminVP"
      },
      "source": [
        "def cleandataframe(dataframeobj):\n",
        "    \"\"\"removes a bunch of atributes unneeded for analysis.\"\"\"\n",
        "    keepers = [\n",
        "        \"wait_time\",\n",
        "        \"from\",\n",
        "        \"date\",\n",
        "        \"text\",\n",
        "        \"photo\",\n",
        "        \"id\",\n",
        "        \"reply_to_message_id\",\n",
        "    ]\n",
        "\n",
        "    def dropper(key):\n",
        "        dataframeobj.drop(key, axis=\"columns\", inplace=True)\n",
        "        return key\n",
        "\n",
        "    x = [dropper(key) for key in dataframeobj.columns if key not in keepers]\n",
        "    return dataframeobj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrHNB-rW4BTd"
      },
      "source": [
        "#### Text analysis helper funcions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB-pBVvD2C1B"
      },
      "source": [
        "def fixtype(msgdict):\n",
        "    \"\"\"augments the message data object with calculated values from\n",
        "    the messages own data. This is necessary to have a correctly typed index\n",
        "    so we cast datetime.datetime from elegrams mercifully chosen ISO date string\n",
        "    We also fix the url in file and photo fields in order to be able to display\n",
        "    this data, you may need to customize the output to your chosen storage\n",
        "    facility, Currently set up for Google Cloud Storage buckets.\n",
        "    \"\"\"\n",
        "\n",
        "    newmsg = msgdict.copy()\n",
        "    newmsg[\"date\"] = datetime.fromisoformat(msgdict[\"date\"])\n",
        "    if \"photo\" in msgdict.keys():\n",
        "        newmsg[\"photo\"] = \"fixurl({})\".format(msgdict[\"photo\"])\n",
        "    if \"file\" in msgdict.keys():\n",
        "        newmsg[\"file\"] = \"fixurl({})\".format(msgdict[\"file\"])\n",
        "    if \"text\" in msgdict.keys and len(msgdict > 0):\n",
        "        newmsg[\"wordcount\"] = text_stats(msgdict[\"text\"])\n",
        "    return newmsg\n",
        "\n",
        "\n",
        "def fixurl(txt):\n",
        "    ...\n",
        "    return txt\n",
        "\n",
        "\n",
        "def text_stats(txt):\n",
        "    wordcount = len(txt.split(\" \"))\n",
        "    ...\n",
        "    return wordcount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzM2FrIduBaq"
      },
      "source": [
        "### Main processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNEu7b0_xNxU"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab.data_table import DataTable\n",
        "\n",
        "\n",
        "def data_generator():\n",
        "    all_messages = []\n",
        "    for f in uploaded:\n",
        "        with open(f, \"r\", encoding=\"utf8\") as chat:\n",
        "            conversation = json.load(chat)\n",
        "            [all_messages.append(msg) for msg in conversation[\"messages\"]]\n",
        "    return (msg for msg in all_messages)\n",
        "\n",
        "\n",
        "def getcolumnvals(column):\n",
        "    all_values = []\n",
        "    for f in uploaded:\n",
        "        with open(f, \"r\", encoding=\"utf8\") as chat:\n",
        "            conversation = json.load(chat)\n",
        "            [all_values.append(msg) for msg in conversation[\"messages\"]]\n",
        "    return (val[column] for val in all_values)\n",
        "\n",
        "\n",
        "messages = data_generator()\n",
        "df = pd.DataFrame.from_records(\n",
        "    [m for m in data_generator()], index=\"date\", coerce_float=False\n",
        ")\n",
        "cleandataframe(df)\n",
        "\n",
        "# deltas = gendeltas(df['date'],\"wait_time\")\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4PEx8GCX7fA"
      },
      "source": [
        "idx = pd.Index([d for d in getcolumnvals(\"date\")], name=\"tstamp\")\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnkVbcwczBO7"
      },
      "source": [
        "df.join(deltas)\n",
        "idx = pd.to_datetime([d for d in getcolumnvals(\"date\")])\n",
        "df.index\n",
        "midx = pd.MultiIndex.from_arrays([idx, df.index], names=[\"tstamp\", \"n\"])\n",
        "\n",
        "# df.resample(\"D\",on=\"date\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPsuYMcteiVI"
      },
      "source": [
        "import altair as alt\n",
        "\n",
        "alt.Chart(df).mark_line().encode(x=\"date:T\", y=\"count\", color=\"symbol\").interactive(\n",
        "    bind_y=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VokLx4lEamFy"
      },
      "source": [
        "from vega_datasets import data\n",
        "\n",
        "stocks = data.stocks()\n",
        "\n",
        "import altair as alt\n",
        "\n",
        "alt.Chart(stocks).mark_line().encode(x=\"date:T\", y=\"price\", color=\"symbol\").interactive(\n",
        "    bind_y=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFhx3qW4XvFh"
      },
      "source": [
        "cdf.loc[:, [\"date\", \"from\", \"text\", \"photo\", \"id\", \"reply_to_message_id\"]]\n",
        "tdf = idf.to_timestamp(copy=True)\n",
        "tdf.info()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}